{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30327e3a"
      },
      "source": [
        "# üöÄ Exploring the openai-agents Library with Gemini\n",
        "This notebook shows how to use the openai-agents library with Gemini API to build conversational agents‚Äîcovering two execution methods"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ installation"
      ],
      "metadata": {
        "id": "wd12XkqwSRxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U2DuZP0_1Iu"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Imports"
      ],
      "metadata": {
        "id": "jL-reb6RR_H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "OE_-gMwUDw8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Imports"
      ],
      "metadata": {
        "id": "MywTysH-Rn2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "dvNo75PtD5YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîê Step 1: Setup for Api Keys"
      ],
      "metadata": {
        "id": "uO3deejXRZw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "print(gemini_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p1ynoc0EDCx",
        "outputId": "ed8eef83-7ef2-4474-da33-6e5536c6e5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIzaSyBcQw_uV9DzZr28gHzmqcokJeWfhZVtw5E\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåê  Step 2: Client Setup for Connecting to **Gemini**"
      ],
      "metadata": {
        "id": "S4GITaFOP526"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "external_client:AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model:OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "IofWknGLEHHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨  Step 3 Running Agent Synchronously"
      ],
      "metadata": {
        "id": "Upg62mcUJUB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent: Agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model=model)\n",
        "\n",
        "result:Runner = Runner.run_sync(agent, \"Hello, how are you.\")\n",
        "\n",
        "print(\"\\nCALLING AGENT\\n\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QgfJqHZJV_M",
        "outputId": "6e6eb860-41b8-481c-fe17-dc80e21dea1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CALLING AGENT\n",
            "\n",
            "Hello there! I'm doing well, thank you for asking. I'm ready to assist you.\n",
            "\n",
            "How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üí¨ Step 3: Running Agent Asynchronously"
      ],
      "metadata": {
        "id": "1m8xnCs4KKG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    agent:Agent = Agent(\n",
        "        name=\"HaikuAssistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result:Runner = await Runner.run(agent, \"Tell me about recursion in programming.\")\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "jZA-iSR9KMJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670de776-805b-440a-dc14-add533e2a625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function calls itself,\n",
            "Until a base case it finds,\n",
            "Solves in small steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7RKgPtw2XlJs"
      }
    }
  ]
}